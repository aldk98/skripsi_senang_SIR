{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from utils import *\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16_bn\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available torchvision models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'AlexNet',\n",
       " 'ResNet',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'VGG',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19_bn',\n",
       " 'vgg19',\n",
       " 'SqueezeNet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'Inception3',\n",
       " 'inception_v3',\n",
       " 'InceptionOutputs',\n",
       " '_InceptionOutputs',\n",
       " 'DenseNet',\n",
       " 'densenet121',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet161',\n",
       " 'googlenet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " '_GoogLeNetOutputs',\n",
       " 'MobileNetV2',\n",
       " 'mobilenet_v2',\n",
       " 'MNASNet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'ShuffleNetV2',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in sys.modules['torchvision.models'].__dict__.items() if callable(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available fastai models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XResNet',\n",
       " 'xresnet18',\n",
       " 'xresnet34',\n",
       " 'xresnet50',\n",
       " 'xresnet101',\n",
       " 'xresnet152',\n",
       " 'xresnet18_deep',\n",
       " 'xresnet34_deep',\n",
       " 'xresnet50_deep',\n",
       " 'ResNet',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'mobilenet_v2',\n",
       " 'SqueezeNet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'densenet121',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet161',\n",
       " 'vgg11_bn',\n",
       " 'vgg13_bn',\n",
       " 'vgg16_bn',\n",
       " 'vgg19_bn',\n",
       " 'alexnet',\n",
       " 'Darknet',\n",
       " 'ResLayer',\n",
       " 'DynamicUnet',\n",
       " 'UnetBlock',\n",
       " 'BasicBlock',\n",
       " 'WideResNet',\n",
       " 'wrn_22',\n",
       " 'xception']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in models.__dict__.items() if callable(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available pretrained models from cadene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fbresnet152',\n",
       " 'cafferesnet101',\n",
       " 'bninception',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_64x4d',\n",
       " 'inceptionv4',\n",
       " 'inceptionresnetv2',\n",
       " 'nasnetalarge',\n",
       " 'nasnetamobile',\n",
       " 'alexnet',\n",
       " 'densenet121',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet161',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'inceptionv3',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19_bn',\n",
       " 'vgg19',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn131',\n",
       " 'dpn107',\n",
       " 'xception',\n",
       " 'senet154',\n",
       " 'se_resnet50',\n",
       " 'se_resnet101',\n",
       " 'se_resnet152',\n",
       " 'se_resnext50_32x4d',\n",
       " 'se_resnext101_32x4d',\n",
       " 'pnasnet5large',\n",
       " 'polynet']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in pretrainedmodels.__dict__.items() if callable(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crappify(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn)\n",
    "    targ_sz = resize_to(img, 96, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    w,h = img.size\n",
    "    q = random.randint(10,70)\n",
    "    ImageDraw.Draw(img).text((random.randint(0,w//2),random.randint(0,h//2)), str(q), fill=(255,255,255))\n",
    "    img.save(dest, quality=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section is for random learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.FakeData at 0x7ff76b20ce80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FakeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /home/aldriankwan/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f56f1f209140eda8877e1e0fedc0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learn = cnn_learner(FakeData(), models.alexnet, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) Sequential  : 13  layers (total: 13)\n",
      "(1) AdaptiveAvgPool2d: 1   layers (total: 14)\n",
      "(2) Sequential  : 7   layers (total: 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "       (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "       (4): ReLU(inplace=True)\n",
       "       (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "       (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (7): ReLU(inplace=True)\n",
       "       (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (9): ReLU(inplace=True)\n",
       "       (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "       (11): ReLU(inplace=True)\n",
       "       (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     )\n",
       "     (1): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "   )\n",
       "   (1): Sequential(\n",
       "     (0): AdaptiveConcatPool2d(\n",
       "       (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "       (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "     )\n",
       "     (1): Flatten()\n",
       "     (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (3): Dropout(p=0.25, inplace=False)\n",
       "     (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (5): ReLU(inplace=True)\n",
       "     (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (7): Dropout(p=0.5, inplace=False)\n",
       "     (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "   )\n",
       " ),\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model,arch_summary(models.alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_groups(nn.Sequential(*learn.model[0], *learn.model[1]), learn.layer_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (4): ReLU(inplace=True)\n",
       "   (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (7): ReLU(inplace=True)\n",
       "   (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (9): ReLU(inplace=True)\n",
       "   (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (11): ReLU(inplace=True)\n",
       "   (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(6, 6)),\n",
       " Sequential(\n",
       "   (0): Dropout(p=0.5, inplace=False)\n",
       "   (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "   (2): ReLU(inplace=True)\n",
       "   (3): Dropout(p=0.5, inplace=False)\n",
       "   (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "   (5): ReLU(inplace=True)\n",
       "   (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in models.alexnet(False).children()]\n",
    "# _alexnet_meta     = {'cut':-1, 'split':_alexnet_split}\n",
    "# def _alexnet_split(m:nn.Module): return (m[0][0][6],m[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model experiments and working towards creating the U-net with resnext model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using resnext architecture, specifically resnext50_32x4d from pytorch model. For pretrained models that are not available on pytorch, we are going to import pretrainedmodels from [Here](https://github.com/Cadene/pretrained-models.pytorch). The goal of this section is to produce a working U-net model with Resnext_50 encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.learner import model_meta\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "import pretrainedmodels\n",
    "from torchvision.models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use oxford pet dataset (yes, not the best, but will do for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/aldriankwan/.fastai/data/oxford-iiit-pet/images')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "path_hr = path/'images'\n",
    "path_llr = path/'small-32'\n",
    "path_lr = path/'small-96'\n",
    "path_mr = path/'small-256'\n",
    "path_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = ImageList.from_folder(path_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_one(fn, i, path, size):\n",
    "    dest = path/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn)\n",
    "    targ_sz = resize_to(img, size, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    img.save(dest, quality=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing to 32 into /home/aldriankwan/.fastai/data/oxford-iiit-pet/small-32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create smaller image sets the first time this nb is run\n",
    "sets = [(path_llr,32),(path_lr, 96), (path_mr, 256)]\n",
    "for p,size in sets:\n",
    "    if not p.exists(): \n",
    "        print(f\"resizing to {size} into {p}\")\n",
    "        parallel(partial(resize_one, path=p, size=size), il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnext50_32x4d(True)\n",
    "# to download the model, use these syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use wrap the torchvision resnext50_34x4d model so it can work.<br>\n",
    "<b>NOTE:</b> be careful when defining models and functions. Remember to only define the function below if models come from pretrainedmodels library instead of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resnext50_32x4d(pretrained=False):\n",
    "#     pretrained = 'imagenet' if pretrained else None\n",
    "#     model = resnext50_32x4d(pretrained=pretrained)\n",
    "#     all_layers = list(model.children())\n",
    "#     return nn.Sequential(*all_layers[0], *all_layers[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block above, I mistook resnext50 for resnext100. resnext50 does exist in pytorch, while resnext100 does not. The code above assumes that the model that will be used comes from pretrainedmodels library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will add meta for the resnext50_34x4d, as it does not exist in fastai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_resnext_meta = {'cut': -2, 'split': lambda m: (m[0][6], m[1]) }\n",
    "model_meta[resnext50_32x4d]=_resnext_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function torchvision.models.alexnet.alexnet(pretrained=False, progress=True, **kwargs)>,\n",
       " <function torchvision.models.resnet.resnet34(pretrained=False, progress=True, **kwargs)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arch_summary(alexnet)\n",
    "alexnet,resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (4): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (5): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "     (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in resnext50_32x4d(False).children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function torchvision.models.resnet.resnext50_32x4d(pretrained=False, progress=True, **kwargs)>,\n",
       " <function torchvision.models.resnet.resnet34(pretrained=False, progress=True, **kwargs)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,size=2,32\n",
    "arch = resnext50_32x4d\n",
    "src = ImageImageList.from_folder(path_lr).split_by_rand_pct(0.1, seed=42)\n",
    "arch,models.resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ImageImageList (6651 items)\n",
       " Image (3, 96, 144),Image (3, 128, 96),Image (3, 96, 128),Image (3, 96, 128),Image (3, 128, 96)\n",
       " Path: /home/aldriankwan/.fastai/data/oxford-iiit-pet/small-96,\n",
       " ImageImageList (739 items)\n",
       " Image (3, 96, 143),Image (3, 96, 141),Image (3, 128, 96),Image (3, 127, 96),Image (3, 96, 141)\n",
       " Path: /home/aldriankwan/.fastai/data/oxford-iiit-pet/small-96,\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.train,src.valid,src.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr/x.name)\n",
    "           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(bs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQEAZABkAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDzZGURYIOMABW5wMetb+otdyW1qYLlo3e3BA5HGW6Y9QAMVx6amN4+U7h1XPX869b0SayXw3FPPbQGRYATkbiCfRu3XtUp3Fe549czasI1ZbedYUyFZIyB+YFdT4Psmujcw3iXCTND+7wyx7Hz8pO4ZOeOhBGe9emab4wsprDc2pIZBKYXg8sqwP8As98e9Y7eGbb+25pYdVMZuP3iQuTuYEDJ3AgnkGiyWw+U8ZjljeeM7eFI/DnpXcnVgk0lsrjbKm7A7VwgtQAWJzjstXbq5hXVoJoXZowiK2c8cAGpTXQSOr06J472SWIIxc/M3cfhVjxHe/btSghgcrJbRBN2SCT1OMd+azILmVPEVnYoDiZRzjk5J/wrMWd5riR3yzgsRk9CTmiew7n/2Q==\n",
      "image/png": "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\n",
      "text/plain": [
       "Image (3, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.valid_ds[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch(ds_type=DatasetType.Valid, rows=2, figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2283, 0.2040, 0.1610,  ..., 0.3323, 0.3304, 0.3254],\n",
      "        [0.2325, 0.2047, 0.1442,  ..., 0.3731, 0.3604, 0.3309],\n",
      "        [0.2343, 0.1803, 0.1085,  ..., 0.4208, 0.3945, 0.3761],\n",
      "        ...,\n",
      "        [0.3662, 0.2239, 0.1777,  ..., 0.4437, 0.4208, 0.3982],\n",
      "        [0.1873, 0.2152, 0.2499,  ..., 0.4026, 0.3784, 0.3714],\n",
      "        [0.2651, 0.2703, 0.2924,  ..., 0.3731, 0.3490, 0.3462]])\n"
     ]
    }
   ],
   "source": [
    "t = data.valid_ds[0][1].data\n",
    "print(t[0])\n",
    "t = torch.stack([t,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1083, 0.0875, 0.0704],\n",
       "         [0.0875, 0.0709, 0.0571],\n",
       "         [0.0704, 0.0571, 0.0463]],\n",
       "\n",
       "        [[0.1083, 0.0875, 0.0704],\n",
       "         [0.0875, 0.0709, 0.0571],\n",
       "         [0.0704, 0.0571, 0.0463]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_matrix(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5, 12, 22, 32, 42],\n",
       " [ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True),\n",
       "  ReLU(inplace=True)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "    \"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "    assert(isinstance(size, torch.Size))\n",
    "    return \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "    \"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "    import gc\n",
    "    total_size = 0\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj):\n",
    "                total_size += obj.numel()\n",
    "            elif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "                if not gpu_only or obj.is_cuda:\n",
    "                    total_size += obj.data.numel()\n",
    "        except Exception as e:\n",
    "            pass        \n",
    "    print(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 123875920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldriankwan/Desktop/python-fastai/.venv/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump_tensors()\n",
    "torch.cuda.empty_cache() \n",
    "if 'resnext_learn' in locals():resnext_learn.destroy()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "resnext_learn = unet_learner(data, arch, wd=wd, loss_func=feat_loss, callback_fns=LossMetrics,\n",
    "                     blur=True, norm_type=NormType.Weight).to_fp16()\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnext_learn.lr_find()\n",
    "# resnext_learn.recorder.plot()\n",
    "# This block will produce OOM in local machine - 2060 super 8GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(None, 0.01, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "slice(lr*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_fit(learn,save_name, lrs=slice(lr), pct_start=0.9):\n",
    "    learn.fit_one_cycle(10, lrs, pct_start=pct_start)\n",
    "    learn.save(save_name)\n",
    "    learn.show_results(rows=1, imgsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>pixel</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>gram_0</th>\n",
       "      <th>gram_1</th>\n",
       "      <th>gram_2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='3325' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.18% [6/3325 00:03<27:45 19.8525]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 7.79 GiB total capacity; 6.43 GiB already allocated; 47.69 MiB free; 6.69 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4211badc0f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnext_learn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-c3b42d818dff>\u001b[0m in \u001b[0;36mdo_fit\u001b[0;34m(learn, save_name, lrs, pct_start)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpct_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/fastai/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/Desktop/python-fastai/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/fastai/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/.venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/python-fastai/.venv/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 7.79 GiB total capacity; 6.43 GiB already allocated; 47.69 MiB free; 6.69 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "do_fit(resnext_learn,'1a',slice(lr*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
